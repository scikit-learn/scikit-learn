{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/arangoml/arangopipe/blob/master/examples/Arangopipe_Feature_Examples.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Installation Prerequisites\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-arango\n",
    "!pip install arangopipe==0.0.6.9.3\n",
    "!pip install pandas PyYAML==5.1.1 sklearn2\n",
    "!pip install jsonpickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Arangopipe for Machine Learning Metadata Management"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine learning model development requires extensive experimentation. Experiments are required for:\n",
    "1. Understanding the characteristics of the data\n",
    "2. Testing hypothesis about the data\n",
    "3. Testing candidate models for a machine learning task.\n",
    "4. Determining the best set of hyper-parameters for a machine learning task.\n",
    "5. Determining the best optimization algorithm for a machine learning task\n",
    "6. Determining the best parameters for an optimization algorithm.\n",
    "7. Determine the effects of various pre-procrossesing tasks on algorithm performance\n",
    "8. Feature selection and feature extraction.\n",
    "9. Best loss function for a machine learning task\n",
    "10. Best model metric to match a business metric.\n",
    "\n",
    "\n",
    "The above list is by no means exhaustive. They are just some of the motivations for performing experiments for machine learning model development. When these experiments are performed, there is a need to capture the results of the experiments and key results in the form of standard machine learning artifacts, for example a notebook used for performing this experiment. There is also a need to organize the data captured from the above experiments in a cohesive manner. Related project activities must be connected. Personel working of machine learning projects must be able to query this data in an adhoc manner to obtain information that they or their co-workers had captured. This is the need for which Arangopipe was created.\n",
    "\n",
    "Arangopipe is a tool for machine learning metadata management using ArangoDB. ArangoDB is a multi-model database and supports a graph and document oriented data model. This makes it a very convinient tool to store meta-data from machine learning experiments. Arangopipe is an API for caturing and analyzing meta-data from machine learning experiments. In this notebook we provide a brief overview of tracking machine learning metadata using Arangopipe. For more information about Arangopipe, please see the [project](https://www.arangodb.com/machine-learning/) page.\n",
    "\n",
    "**NOTE:**\n",
    "\n",
    "\n",
    "You should be able to run this notebook without installing ArangoDB. The notebook connects to a managed service (cloud) instance of ArangoDB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To use Arangopipe to track meta-data for projects, projects have to be registered with Arangopipe. For purposes of illustration, we will use the california housing dataset from UCI machine learning repository. Our project entails developing a regression model with this dataset. We will first register this project with Arangopipe as shown below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from arangopipe.arangopipe_storage.arangopipe_api import ArangoPipe\n",
    "from arangopipe.arangopipe_storage.arangopipe_admin_api import ArangoPipeAdmin\n",
    "from arangopipe.arangopipe_storage.arangopipe_config import ArangoPipeConfig\n",
    "from arangopipe.arangopipe_storage.managed_service_conn_parameters import ManagedServiceConnParam\n",
    "mdb_config = ArangoPipeConfig()\n",
    "msc = ManagedServiceConnParam()\n",
    "conn_params = { msc.DB_SERVICE_HOST : \"arangoml.arangodb.cloud\", \\\n",
    "                        msc.DB_SERVICE_END_POINT : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_NAME : \"createDB\",\\\n",
    "                        msc.DB_SERVICE_PORT : 8529,\\\n",
    "                        msc.DB_CONN_PROTOCOL : 'https'}\n",
    "        \n",
    "mdb_config = mdb_config.create_connection_config(conn_params)\n",
    "admin = ArangoPipeAdmin(reuse_connection = False, config = mdb_config)\n",
    "ap_config = admin.get_config()\n",
    "ap = ArangoPipe(config = ap_config)\n",
    "proj_info = {\"name\": \"Housing_Price_Estimation_Project\"}\n",
    "proj_reg = admin.register_project(proj_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the details of capturing meta-data with Arangopipe as part of model building activity will be illustrated. Model selection is an important activity for data scientists. Data scientists consider many candidate models for a task. The best performing model is then chosen. This procedure is illustrated in the notebook illustrating the use of hyperopt to capture meta data from a hyper-parameter tuning experiment, (see [hyperopt.](https://github.com/arangoml/arangopipe/blob/master/arangopipe/tests/hyperopt/hyperopt_integration.ipynb)). We will use a simpler setting for this notebook. We will assume model selection has been completed and that a LASSO regression model is the best candidate for the task. Having made this decision, we capture information about the model and its parameters. This information is stored in Arangopipe. The details of performing these tasks are shown below. Before model building, we capture information related to the dataset and the features used to build the model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read a copy of the dataset from the Arangopipe repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data_url = \"https://raw.githubusercontent.com/arangoml/arangopipe/arangopipe_examples/examples/data/cal_housing.csv\"\n",
    "df = pd.read_csv(data_url, error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register it with Arangopipe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ds_info = {\"name\" : \"california-housing-dataset\",\\\n",
    "            \"description\": \"This dataset lists median house prices in Califoria. Various house features are provided\",\\\n",
    "           \"source\": \"UCI ML Repository\" }\n",
    "ds_reg = ap.register_dataset(ds_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register Featureset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Register the features used to develop the model.\n",
    "\n",
    "\n",
    "*   Note that the response variable has been log transformed\n",
    "*   Note that when the featureset is registered, it is linked to the dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "df[\"medianHouseValue\"] = df[\"medianHouseValue\"].apply(lambda x: np.log(x))\n",
    "featureset = df.dtypes.to_dict()\n",
    "featureset = {k:str(featureset[k]) for k in featureset}\n",
    "featureset[\"name\"] = \"log_transformed_median_house_value\"\n",
    "fs_reg = ap.register_featureset(featureset, ds_reg[\"_key\"]) # note that the dataset and featureset are linked here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data Summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.hist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Develop a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create test and training sets for the model building activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "preds = df.columns.to_list()\n",
    "preds.remove('medianHouseValue')\n",
    "X = df[preds].values\n",
    "Y = df['medianHouseValue'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit a Lasso model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Lasso model is developed. Train and test performances are noted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.metrics import mean_squared_error\n",
    "clf = linear_model.Lasso(alpha=0.001)\n",
    "clf.fit(X_train, y_train)\n",
    "train_pred = clf.predict(X_train)\n",
    "test_pred = clf.predict(X_test)\n",
    "train_mse = mean_squared_error(train_pred, y_train)\n",
    "test_mse = mean_squared_error(test_pred, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Register the Model\n",
    "* Note that project and model are linked\n",
    "* The notebook associated withe the model can be retreived from github. This can be part of the meta-data associated with the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import requests\n",
    "url = ('https://raw.githubusercontent.com/arangoml/arangopipe/master/examples/Arangopipe_Feature_Examples.ipynb')\n",
    "nbjson = requests.get(url).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_info = {\"name\": \"Lasso Model for Housing Dataset\",  \"task\": \"Regression\", 'notebook': nbjson}\n",
    "model_reg = ap.register_model(model_info, project = \"Housing_Price_Estimation_Project\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Model Building Activity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section the details of capturing a consolidated version of this model building activity. The execution of this notebook, or any ML activity, is captured by the 'Run' entity in the Arangopipe schema (see [schema](https://github.com/arangoml/arangopipe)). To record the execution, we need to create a unique identifier for it in ArangoDB. After generating a unique identifier, we capture the model parameters and model performance and then record the details of this experiment in Arangopipe. Each of these steps is shown below.\n",
    "\n",
    "Note: Model parameters are important metadata. Results from model building activity are converted to JSON for storage in ArangoDB. We are now getting ready to create a consolidated capture of the activities performed in this notebook in Arangopipe. To do so, we need to create a unique identifier for this activity. These are shown below.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that capturing the 'Run' or execution of this cell captures information that links\n",
    "\n",
    "\n",
    "1.   The dataset used in this execution (ds_reg)\n",
    "2.   The featureset used in this execution (fs_reg)\n",
    "3.   The model parameters used in this execution (model_params)\n",
    "4.   The model performance that was observed in this execution (model perf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "import datetime\n",
    "import jsonpickle\n",
    "\n",
    "ruuid = str(uuid.uuid4().int)\n",
    "model_perf = {'training_mse': train_mse, 'test_mse': test_mse, 'run_id': ruuid, \"timestamp\": str(datetime.datetime.now())}\n",
    "\n",
    "mp = clf.get_params()\n",
    "mp = jsonpickle.encode(mp)\n",
    "model_params = {'run_id': ruuid, 'model_params': mp}\n",
    "\n",
    "run_info = {\"dataset\" : ds_reg[\"_key\"],\\\n",
    "                    \"featureset\": fs_reg[\"_key\"],\\\n",
    "                    \"run_id\": ruuid,\\\n",
    "                    \"model\": model_reg[\"_key\"],\\\n",
    "                    \"model-params\": model_params,\\\n",
    "                    \"model-perf\": model_perf,\\\n",
    "                    \"tag\": \"Housing_Price_Estimation_Project\",\\\n",
    "                    \"project\": \"Housing_Price_Estimation_Project\"}\n",
    "ap.log_run(run_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the connection information to google drive so that this can used to connect to the instance that was used in this session,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "fp = '/content/drive/My Drive/saved_arangopipe_config.yaml'\n",
    "mdb_config.export_cfg(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Arangopipe with Common Tools in a Machine Learning Stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook provides the details of working with Arangopipe to capture meta-data from a machine learning project activity. If you would like to see Arangopipe can be used with some common tools in a machine learning stack:\n",
    "\n",
    "\n",
    "1.   See [TFX](https://github.com/arangoml/arangopipe/tree/master/arangopipe/tests/TFX) for the details of using Arangopipe with TFX\n",
    "2.   See [Pytorch](https://github.com/arangoml/arangopipe/tree/master/arangopipe/tests/pytorch) for details of using Arangopipe with Pytorch.\n",
    "3.  See [Hyperopt](https://github.com/arangoml/arangopipe/tree/master/arangopipe/tests/hyperopt) for details of using Arangopipe with Hyperopt\n",
    "4. See [MLFlow](https://github.com/arangoml/arangopipe/tree/master/arangopipe/tests/mlflow) for details of using Arangopipe with MLFlow.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
